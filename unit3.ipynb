{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7xBVPzoXxOg"
   },
   "source": [
    "# Unit 3: Deep Q-Learning with Atari Games 👾 using RL Baselines3 Zoo\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/thumbnail.jpg\" alt=\"Unit 3 Thumbnail\">\n",
    "\n",
    "In this notebook, **you'll train a Deep Q-Learning agent** playing Space Invaders using [RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo), a training framework based on [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) that provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n",
    "\n",
    "We're using the [RL-Baselines-3 Zoo integration, a vanilla version of Deep Q-Learning](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html) with no extensions such as Double-DQN, Dueling-DQN, and Prioritized Experience Replay.\n",
    "\n",
    "⬇️ Here is an example of what **you will achieve** ⬇️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9S713biXntc"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-SpaceInvadersNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykJiGevCMVc5"
   },
   "source": [
    "### 🎮 Environments:\n",
    "\n",
    "- [SpacesInvadersNoFrameskip-v4](https://gymnasium.farama.org/environments/atari/space_invaders/)\n",
    "\n",
    "You can see the difference between Space Invaders versions here 👉 https://gymnasium.farama.org/environments/atari/space_invaders/#variants\n",
    "\n",
    "### 📚 RL-Library:\n",
    "\n",
    "- [RL-Baselines3-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wciHGjrFYz9m"
   },
   "source": [
    "## Objectives of this notebook 🏆\n",
    "At the end of the notebook, you will:\n",
    "- Be able to understand deeper **how RL Baselines3 Zoo works**.\n",
    "- Be able to **push your trained agent and the code to the Hub** with a nice video replay and an evaluation score 🔥.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsnP0rjxMn1e"
   },
   "source": [
    "## This notebook is from Deep Reinforcement Learning Course\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw6fJHIAZd-J"
   },
   "source": [
    "In this free course, you will:\n",
    "\n",
    "- 📖 Study Deep Reinforcement Learning in **theory and practice**.\n",
    "- 🧑‍💻 Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
    "- 🤖 Train **agents in unique environments**\n",
    "\n",
    "And more check 📚 the syllabus 👉 https://simoninithomas.github.io/deep-rl-course\n",
    "\n",
    "Don’t forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to **send you the links when each Unit is published and give you information about the challenges and updates).**\n",
    "\n",
    "\n",
    "The best way to keep in touch is to join our discord server to exchange with the community and with us 👉🏻 https://discord.gg/ydHrjt3WP5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vgANIBBZg1p"
   },
   "source": [
    "## Prerequisites 🏗️\n",
    "Before diving into the notebook, you need to:\n",
    "\n",
    "🔲 📚 **[Study Deep Q-Learning by reading Unit 3](https://huggingface.co/deep-rl-course/unit3/introduction)**  🤗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kszpGFaRVhq"
   },
   "source": [
    "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QR0jZtYreSI5"
   },
   "source": [
    "# Let's train a Deep Q-Learning agent playing Atari' Space Invaders 👾 and upload it to the Hub.\n",
    "\n",
    "We strongly recommend students **to use Google Colab for the hands-on exercises instead of running them on their personal computers**.\n",
    "\n",
    "By using Google Colab, **you can focus on learning and experimenting without worrying about the technical aspects of setting up your environments**.\n",
    "\n",
    "To validate this hands-on for the certification process, you need to push your trained model to the Hub and **get a result of >= 200**.\n",
    "\n",
    "To find your result, go to the leaderboard and find your model, **the result = mean_reward - std of reward**\n",
    "\n",
    "For more information about the certification process, check this section 👉 https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc8BnyVEc3Ys"
   },
   "source": [
    "## An advice 💡\n",
    "It's better to run this colab in a copy on your Google Drive, so that **if it timeouts** you still have the saved notebook on your Google Drive and do not need to fill everything from scratch.\n",
    "\n",
    "To do that you can either do `Ctrl + S` or `File > Save a copy in Google Drive.`\n",
    "\n",
    "Also, we're going to **train it for 90 minutes with 1M timesteps**. By typing `!nvidia-smi` will tell you what GPU you're using.\n",
    "\n",
    "And if you want to train more such 10 million steps, this will take about 9 hours, potentially resulting in Colab timing out. In that case, I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4FVzaoM6fC"
   },
   "source": [
    "## Set the GPU 💪\n",
    "- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV0NyFdQM9ZG"
   },
   "source": [
    "- `Hardware Accelerator > GPU`\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS_cVefO-aYg"
   },
   "source": [
    "# Install RL-Baselines3 Zoo and its dependencies 📚\n",
    "\n",
    "If you see `ERROR: pip's dependency resolver does not currently take into account all the packages that are installed.` **this is normal and it's not a critical error** there's a conflict of version. But the packages we need are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S1A_E4z3awa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/DLR-RM/rl-baselines3-zoo\n",
      "  Cloning https://github.com/DLR-RM/rl-baselines3-zoo to /tmp/pip-req-build-40tl6kbk\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/rl-baselines3-zoo /tmp/pip-req-build-40tl6kbk\n",
      "  Resolved https://github.com/DLR-RM/rl-baselines3-zoo to commit 325ef5dafe46e483ce9d727d2851aff18b70db7c\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sb3_contrib<3.0,>=2.6.0 (from rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for sb3_contrib<3.0,>=2.6.0 from https://files.pythonhosted.org/packages/35/0b/2aa9be7796c372d17400d55f90f19ddc5b1b242cb996db0bf9ae6ee370e8/sb3_contrib-2.6.0-py3-none-any.whl.metadata\n",
      "  Downloading sb3_contrib-2.6.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from rl_zoo3==2.6.0) (1.0.0)\n",
      "Requirement already satisfied: huggingface_sb3<4.0,>=3.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from rl_zoo3==2.6.0) (3.0)\n",
      "Requirement already satisfied: tqdm in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from rl_zoo3==2.6.0) (4.67.1)\n",
      "Collecting rich (from rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting optuna>=3.0 (from rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for optuna>=3.0 from https://files.pythonhosted.org/packages/28/09/c4d329f7969443cdd4d482048ca406b6f61cda3c8e99ace71feaec7c8734/optuna-4.2.1-py3-none-any.whl.metadata\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from rl_zoo3==2.6.0) (6.0.2)\n",
      "Collecting pytablewriter~=1.2 (from rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for pytablewriter~=1.2 from https://files.pythonhosted.org/packages/21/4c/c199512f01c845dfe5a7840ab3aae6c60463b5dc2a775be72502dfd9170a/pytablewriter-1.2.1-py3-none-any.whl.metadata\n",
      "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting shimmy~=2.0 (from rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for shimmy~=2.0 from https://files.pythonhosted.org/packages/4e/e9/64879ed81025b73865a0b6e5668735bf0b71feff5abb6e7a2bee2a1deae9/Shimmy-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->rl_zoo3==2.6.0) (2.2.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->rl_zoo3==2.6.0) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->rl_zoo3==2.6.0) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->rl_zoo3==2.6.0) (0.0.4)\n",
      "Requirement already satisfied: huggingface-hub~=0.8 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (0.29.3)\n",
      "Requirement already satisfied: wasabi in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (1.1.3)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.0->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/41/18/d89a443ed1ab9bcda16264716f809c663866d4ca8de218aa78fd50b38ead/alembic-1.15.2-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna>=3.0->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for colorlog from https://files.pythonhosted.org/packages/e3/51/9b208e85196941db2f0654ad0357ca6388ab3ed67efdbfc799f35d1f83aa/colorlog-6.9.0-py3-none-any.whl.metadata\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from optuna>=3.0->rl_zoo3==2.6.0) (24.2)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna>=3.0->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for sqlalchemy>=1.4.2 from https://files.pythonhosted.org/packages/12/cf/b891a8c1d0c27ce9163361664c2128c7a57de3f35000ea5202eb3a2917b7/sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from pytablewriter~=1.2->rl_zoo3==2.6.0) (65.5.0)\n",
      "Collecting DataProperty<2,>=1.1.0 (from pytablewriter~=1.2->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for DataProperty<2,>=1.1.0 from https://files.pythonhosted.org/packages/21/c2/e12e95e289e6081a40454199ab213139ef16a528c7c86432de545b05a23a/DataProperty-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter~=1.2->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for mbstrdecoder<2,>=1.0.0 from https://files.pythonhosted.org/packages/30/ac/5ce64a1d4cce00390beab88622a290420401f1cabf05caf2fc0995157c21/mbstrdecoder-1.1.4-py3-none-any.whl.metadata\n",
      "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter~=1.2->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for pathvalidate<4,>=2.3.0 from https://files.pythonhosted.org/packages/50/14/c5a0e1a947909810fc4c043b84cac472b70e438148d34f5393be1bac663f/pathvalidate-3.2.3-py3-none-any.whl.metadata\n",
      "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter~=1.2->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for tabledata<2,>=1.3.1 from https://files.pythonhosted.org/packages/08/64/fa4160151976ee4b2cf0c1217a99443ffaeb991956feddfeac9eee9952f8/tabledata-1.3.4-py3-none-any.whl.metadata\n",
      "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter~=1.2->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for tcolorpy<1,>=0.0.5 from https://files.pythonhosted.org/packages/05/a2/ed023f2edd1e011b4d99b6727bce8253842d66c3fbf9ed0a26fc09a92571/tcolorpy-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter~=1.2->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for typepy[datetime]<2,>=1.3.2 from https://files.pythonhosted.org/packages/ee/31/e393c3830bdedd01735bd195c85ac3034b6bcaf6c18142bab60a4047ca36/typepy-1.3.4-py3-none-any.whl.metadata\n",
      "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting stable_baselines3<3.0,>=2.6.0 (from sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for stable_baselines3<3.0,>=2.6.0 from https://files.pythonhosted.org/packages/54/60/6900e8186168e6e23a2125655fb4fe53130256480cc7950dadcee030cd67/stable_baselines3-2.6.0-py3-none-any.whl.metadata\n",
      "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from rich->rl_zoo3==2.6.0) (2.19.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=3.0->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/cd/83/de0a49e7de540513f53ab5d2e105321dedeb08a8f5850f0208decf4390ec/Mako-1.3.9-py3-none-any.whl.metadata\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: filelock in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (2025.3.0)\n",
      "Requirement already satisfied: requests in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (2.32.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter~=1.2->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for chardet<6,>=3.0.4 from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna>=3.0->rl_zoo3==2.6.0)\n",
      "  Obtaining dependency information for greenlet>=1 from https://files.pythonhosted.org/packages/f7/4b/1c9695aa24f808e156c8f4813f685d975ca73c000c2a5056c514c64980f6/greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Using cached greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (2.6.0)\n",
      "Requirement already satisfied: pandas in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (3.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.6.0) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.6.0) (1.17.0)\n",
      "Requirement already satisfied: networkx in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna>=3.0->rl_zoo3==2.6.0) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (3.2.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from pandas->stable_baselines3<3.0,>=2.6.0->sb3_contrib<3.0,>=2.6.0->rl_zoo3==2.6.0) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.6.0) (2025.1.31)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sb3_contrib-2.6.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
      "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rl_zoo3\n",
      "  Building wheel for rl_zoo3 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rl_zoo3: filename=rl_zoo3-2.6.0-py3-none-any.whl size=77819 sha256=2bc4ad4fd09d3253da4d8945e1ce9aa7314be2eef3779782c21f751ba9e93b0f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6jdn_wbo/wheels/79/a7/a1/afc7c6c739a99c02b2cba585d219d453a80ab2bff20fb6526f\n",
      "Successfully built rl_zoo3\n",
      "Installing collected packages: tcolorpy, pathvalidate, mdurl, Mako, greenlet, colorlog, chardet, sqlalchemy, shimmy, mbstrdecoder, markdown-it-py, typepy, rich, alembic, stable_baselines3, optuna, sb3_contrib, DataProperty, tabledata, pytablewriter, rl_zoo3\n",
      "  Attempting uninstall: stable_baselines3\n",
      "    Found existing installation: stable_baselines3 2.5.0\n",
      "    Uninstalling stable_baselines3-2.5.0:\n",
      "      Successfully uninstalled stable_baselines3-2.5.0\n",
      "Successfully installed DataProperty-1.1.0 Mako-1.3.9 alembic-1.15.2 chardet-5.2.0 colorlog-6.9.0 greenlet-3.1.1 markdown-it-py-3.0.0 mbstrdecoder-1.1.4 mdurl-0.1.2 optuna-4.2.1 pathvalidate-3.2.3 pytablewriter-1.2.1 rich-14.0.0 rl_zoo3-2.6.0 sb3_contrib-2.6.0 shimmy-2.0.0 sqlalchemy-2.0.40 stable_baselines3-2.6.0 tabledata-1.3.4 tcolorpy-0.1.7 typepy-1.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/DLR-RM/rl-baselines3-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_MllY6Om1eI"
   },
   "outputs": [],
   "source": [
    "# !apt-get install swig cmake ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S9mJiKg6SqC"
   },
   "source": [
    "To be able to use Atari games in Gymnasium we need to install atari package. And accept-rom-license to download the rom files (games files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NsRP-lX1_2fC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[atari] in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium[atari]) (2.2.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium[atari]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium[atari]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Collecting ale-py>=0.9 (from gymnasium[atari])\n",
      "  Obtaining dependency information for ale-py>=0.9 from https://files.pythonhosted.org/packages/64/ad/248269043741db244fd7bd6402b7f9efcf0409228e29b7978e64a2300899/ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
      "Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ale-py\n",
      "Successfully installed ale-py-0.10.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: gymnasium[accept-rom-license] in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (1.0.0)\n",
      "\u001b[33mWARNING: gymnasium 1.0.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium[accept-rom-license]) (2.2.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium[accept-rom-license]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium[accept-rom-license]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/gluonhiggs/.pyenv/versions/3.11.5/envs/DeepRLCourse-dev/lib/python3.11/site-packages (from gymnasium[accept-rom-license]) (0.0.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[atari]\n",
    "!pip install gymnasium[accept-rom-license]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTpYcVZVMzUI"
   },
   "source": [
    "## Create a virtual display 🔽\n",
    "\n",
    "During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n",
    "\n",
    "Hence the following cell will install the librairies and create and run a virtual screen 🖥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV6wjQ7Be7p5"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt install python-opengl\n",
    "!apt install xvfb\n",
    "!pip3 install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BE5JWP5rQIKf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7fdfc3cec850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Virtual display\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iPgzluo9z-u"
   },
   "source": [
    "## Train our Deep Q-Learning Agent to Play Space Invaders 👾\n",
    "\n",
    "To train an agent with RL-Baselines3-Zoo, we just need to do two things:\n",
    "\n",
    "1. Create a hyperparameter config file that will contain our training hyperparameters called `dqn.yml`.\n",
    "\n",
    "This is a template example:\n",
    "\n",
    "```\n",
    "SpaceInvadersNoFrameskip-v4:\n",
    "  env_wrapper:\n",
    "    - stable_baselines3.common.atari_wrappers.AtariWrapper\n",
    "  frame_stack: 4\n",
    "  policy: 'CnnPolicy'\n",
    "  n_timesteps: !!float 1e6\n",
    "  buffer_size: 100000\n",
    "  learning_rate: !!float 1e-4\n",
    "  batch_size: 32\n",
    "  learning_starts: 100000\n",
    "  target_update_interval: 1000\n",
    "  train_freq: 4\n",
    "  gradient_steps: 1\n",
    "  exploration_fraction: 0.1\n",
    "  exploration_final_eps: 0.01\n",
    "  # If True, you need to deactivate handle_timeout_termination\n",
    "  # in the replay_buffer_kwargs\n",
    "  optimize_memory_usage: False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VjblFSVDQOj"
   },
   "source": [
    "Here we see that:\n",
    "- We use the `Atari Wrapper` that preprocess the input (Frame reduction ,grayscale, stack 4 frames)\n",
    "- We use `CnnPolicy`, since we use Convolutional layers to process the frames\n",
    "- We train it for 10 million `n_timesteps`\n",
    "- Memory (Experience Replay) size is 100000, aka the amount of experience steps you saved to train again your agent with.\n",
    "\n",
    "💡 My advice is to **reduce the training timesteps to 1M,** which will take about 90 minutes on a P100. `!nvidia-smi` will tell you what GPU you're using. At 10 million steps, this will take about 9 hours, which could likely result in Colab timing out. I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qTkbWrkECOJ"
   },
   "source": [
    "In terms of hyperparameters optimization, my advice is to focus on these 3 hyperparameters:\n",
    "- `learning_rate`\n",
    "- `buffer_size (Experience Memory size)`\n",
    "- `batch_size`\n",
    "\n",
    "As a good practice, you need to **check the documentation to understand what each hyperparameters does**: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hn8bRTHvERRL"
   },
   "source": [
    "2. We start the training and save the models on `logs` folder 📁\n",
    "\n",
    "- Define the algorithm after `--algo`, where we save the model after `-f` and where the hyperparameter config is after `-c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xr1TVW4xfbz3"
   },
   "outputs": [],
   "source": [
    "!python -m rl_zoo3.train --algo ________ --env SpaceInvadersNoFrameskip-v4  -f _________  -c _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeChoX-3SZfP"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuocgdokSab9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== SpaceInvadersNoFrameskip-v4 ==========\n",
      "Seed: 986468666\n",
      "Loading hyperparameters from: dqn.yml\n",
      "Default hyperparameters for environment (ones being tuned will be overridden):\n",
      "OrderedDict([('batch_size', 64),\n",
      "             ('buffer_size', 100000),\n",
      "             ('env_wrapper',\n",
      "              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n",
      "             ('exploration_final_eps', 0.09178937437643139),\n",
      "             ('exploration_fraction', 0.3178717485441687),\n",
      "             ('frame_stack', 3),\n",
      "             ('gradient_steps', 5),\n",
      "             ('learning_rate', 4.964132854171392e-05),\n",
      "             ('learning_starts', 110000),\n",
      "             ('n_timesteps', 1000000.0),\n",
      "             ('optimize_memory_usage', False),\n",
      "             ('policy', 'CnnPolicy'),\n",
      "             ('target_update_interval', 4000),\n",
      "             ('train_freq', 2)])\n",
      "Using 1 environments\n",
      "Creating test environment\n",
      "A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)\n",
      "[Powered by Stella]\n",
      "Stacking 3 frames\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Stacking 3 frames\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Using cuda device\n",
      "Log path: logs//dqn/SpaceInvadersNoFrameskip-v4_4\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.14e+03 |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 393      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | 47.5     |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1043     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 945      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.53e+03 |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1079     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1490     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.53e+03 |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1092     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2008     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1132     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2804     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | 128      |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1166     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3918     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1163     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4481     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.96e+03 |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1174     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 5207     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | 152      |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1183     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 5928     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 148      |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1187     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 6465     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 145      |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1192     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 7193     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | 139      |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1192     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 7586     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 138      |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1197     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 8398     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | 134      |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 1197     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 8804     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | 128      |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 1197     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 9243     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | 128      |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 1199     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 10105    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 140      |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 1204     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 11083    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 146      |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 1206     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 11888    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 154      |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 1208     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 12627    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | 149      |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 1208     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 13125    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 147      |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 1208     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 13580    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | 149      |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 1211     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 14596    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | 158      |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 1211     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 15021    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 154      |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 1212     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 15589    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 151      |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1213     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 16246    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | 154      |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 1216     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 17508    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 161      |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 1216     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 18017    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 159      |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 1217     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 18691    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | 161      |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 1218     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 19343    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 156      |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 1218     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 19879    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 160      |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 1219     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 20639    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 1221     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 21792    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 1222     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 22710    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 175      |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 1222     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 23244    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 170      |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 1222     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 23878    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 171      |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 1223     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 24745    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=244.00 +/- 120.93\n",
      "Episode length: 2562.40 +/- 747.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.56e+03 |\n",
      "|    mean_reward      | 244      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 171      |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 1049     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 25255    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 173      |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 1053     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 25968    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 172      |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 1054     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 26574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 170      |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 1059     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 27355    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 1058     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 27872    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 1061     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 28391    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 1063     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 28988    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 1064     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 29575    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 163      |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 1066     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 30153    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 1066     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 31191    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 1066     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 31842    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 1069     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 32734    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 1071     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 33383    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 163      |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 1074     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 34195    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 162      |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 1076     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 34815    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 161      |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 1080     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 35752    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 1081     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 36377    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 1081     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 37208    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 1080     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 37951    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 1081     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 38644    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | 166      |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 1084     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 39689    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 1086     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 40288    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 1088     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 41016    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 1090     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 41545    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 1092     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 42487    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 1093     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 43071    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 1095     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 43786    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 1096     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 44338    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | 162      |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 1097     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 44986    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | 162      |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 1098     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 45684    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | 162      |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 1100     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 46444    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 1100     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 47288    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 165      |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 1102     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 48183    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 1102     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 48635    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 1104     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 49583    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=74.00 +/- 39.67\n",
      "Episode length: 1532.60 +/- 381.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 1.53e+03 |\n",
      "|    mean_reward      | 74       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 1060     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 50211    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 1062     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 50926    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | 169      |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 1063     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 51913    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | 168      |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 1064     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 52470    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | 172      |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 1066     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 53093    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | 173      |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 1068     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 53944    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python -m rl_zoo3.train --algo dqn  --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dLomIiMKQaf"
   },
   "source": [
    "## Let's evaluate our agent 👀\n",
    "- RL-Baselines3-Zoo provides `enjoy.py`, a python script to evaluate our agent. In most RL libraries, we call the evaluation script `enjoy.py`.\n",
    "- Let's evaluate it for 5000 timesteps 🔥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "co5um_KeKbBJ"
   },
   "outputs": [],
   "source": [
    "!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps _________  --folder logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q24K1tyWSj7t"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P_uSmwGRSk0z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest experiment, id=2\n",
      "Loading logs/dqn/SpaceInvadersNoFrameskip-v4_2/SpaceInvadersNoFrameskip-v4.zip\n",
      "A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)\n",
      "[Powered by Stella]\n",
      "Stacking 4 frames\n",
      "Atari Episode Score: 395.00\n",
      "Atari Episode Length 3615\n",
      "Atari Episode Score: 380.00\n",
      "Atari Episode Length 3665\n",
      "Atari Episode Score: 540.00\n",
      "Atari Episode Length 3795\n",
      "Atari Episode Score: 600.00\n",
      "Atari Episode Length 3857\n",
      "Atari Episode Score: 665.00\n",
      "Atari Episode Length 3345\n"
     ]
    }
   ],
   "source": [
    "!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking 4 frames\n",
    "Atari Episode Score: 395.00\n",
    "Atari Episode Length 3615\n",
    "Atari Episode Score: 380.00\n",
    "Atari Episode Length 3665\n",
    "Atari Episode Score: 540.00\n",
    "Atari Episode Length 3795\n",
    "Atari Episode Score: 600.00\n",
    "Atari Episode Length 3857\n",
    "Atari Episode Score: 665.00\n",
    "Atari Episode Length 3345\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liBeTltiHJtr"
   },
   "source": [
    "## Publish our trained model on the Hub 🚀\n",
    "Now that we saw we got good results after the training, we can publish our trained model on the hub 🤗 with one line of code.\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/space-invaders-model.gif\" alt=\"Space Invaders model\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezbHS1q3HYVV"
   },
   "source": [
    "By using `rl_zoo3.push_to_hub` **you evaluate, record a replay, generate a model card of your agent and push it to the hub**.\n",
    "\n",
    "This way:\n",
    "- You can **showcase our work** 🔥\n",
    "- You can **visualize your agent playing** 👀\n",
    "- You can **share with the community an agent that others can use** 💾\n",
    "- You can **access a leaderboard 🏆 to see how well your agent is performing compared to your classmates** 👉  https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMSeZRBiHk6X"
   },
   "source": [
    "To be able to share your model with the community there are three more steps to follow:\n",
    "\n",
    "1️⃣ (If it's not already done) create an account to HF ➡ https://huggingface.co/join\n",
    "\n",
    "2️⃣ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
    "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9O6FI0F8HnzE"
   },
   "source": [
    "- Copy the token\n",
    "- Run the cell below and past the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ppu9yePwHrZX"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
    "notebook_login()\n",
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RVEdunPHs8B"
   },
   "source": [
    "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSLwdmvhHvjw"
   },
   "source": [
    "3️⃣ We're now ready to push our trained agent to the 🤗 Hub 🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PW436XnhHw1H"
   },
   "source": [
    "Let's run push_to_hub.py file to upload our trained agent to the Hub.\n",
    "\n",
    "`--repo-name `: The name of the repo\n",
    "\n",
    "`-orga`: Your Hugging Face username\n",
    "\n",
    "`-f`: Where the trained model folder is (in our case `logs`)\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/select-id.png\" alt=\"Select Id\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ygk2sEktTDEw"
   },
   "outputs": [],
   "source": [
    "!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name _____________________ -orga _____________________ -f logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otgpa0rhS9wR"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HQNlAXuEhci"
   },
   "outputs": [],
   "source": [
    "!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name dqn-SpaceInvadersNoFrameskip-v4  -orga ThomasSimonini  -f logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D4F5zsTTJ-L"
   },
   "source": [
    "###."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff89kd2HL1_s"
   },
   "source": [
    "Congrats 🥳 you've just trained and uploaded your first Deep Q-Learning agent using RL-Baselines-3 Zoo. The script above should have displayed a link to a model repository such as https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4. When you go to this link, you can:\n",
    "\n",
    "- See a **video preview of your agent** at the right.\n",
    "- Click \"Files and versions\" to see all the files in the repository.\n",
    "- Click \"Use in stable-baselines3\" to get a code snippet that shows how to load the model.\n",
    "- A model card (`README.md` file) which gives a description of the model and the hyperparameters you used.\n",
    "\n",
    "Under the hood, the Hub uses git-based repositories (don't worry if you don't know what git is), which means you can update the model with new versions as you experiment and improve your agent.\n",
    "\n",
    "**Compare the results of your agents with your classmates** using the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) 🏆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyRKcCYY-dIo"
   },
   "source": [
    "## Load a powerful trained model 🔥\n",
    "- The Stable-Baselines3 team uploaded **more than 150 trained Deep Reinforcement Learning agents on the Hub**.\n",
    "\n",
    "You can find them here: 👉 https://huggingface.co/sb3\n",
    "\n",
    "Some examples:\n",
    "- Asteroids: https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4\n",
    "- Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n",
    "- Breakout: https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4\n",
    "- Road Runner: https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4\n",
    "\n",
    "Let's load an agent playing Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-9QVFIROI5Y"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<video controls autoplay><source src=\"https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZQNY_r6NJtC"
   },
   "source": [
    "1. We download the model using `rl_zoo3.load_from_hub`, and place it in a new folder that we can call `rl_trained`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdBNZHy0NGTR"
   },
   "outputs": [],
   "source": [
    "# Download model and save it into the logs/ folder\n",
    "!python -m rl_zoo3.load_from_hub --algo dqn --env BeamRiderNoFrameskip-v4 -orga sb3 -f rl_trained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFt6hmWsNdBo"
   },
   "source": [
    "2. Let's evaluate if for 5000 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOxs0rNuN0uS"
   },
   "outputs": [],
   "source": [
    "!python -m rl_zoo3.enjoy --algo dqn --env BeamRiderNoFrameskip-v4 -n 5000  -f rl_trained/ --no-render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxMDuDfPON57"
   },
   "source": [
    "Why not trying to train your own **Deep Q-Learning Agent playing BeamRiderNoFrameskip-v4? 🏆.**\n",
    "\n",
    "If you want to try, check https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters **in the model card, you have the hyperparameters of the trained agent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xL_ZtUgpOuY6"
   },
   "source": [
    "But finding hyperparameters can be a daunting task. Fortunately, we'll see in the next Unit, how we can **use Optuna for optimizing the Hyperparameters 🔥.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pqaco8W-huW"
   },
   "source": [
    "## Some additional challenges 🏆\n",
    "The best way to learn **is to try things by your own**!\n",
    "\n",
    "In the [Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) you will find your agents. Can you get to the top?\n",
    "\n",
    "Here's a list of environments you can try to train your agent with:\n",
    "- BeamRiderNoFrameskip-v4\n",
    "- BreakoutNoFrameskip-v4\n",
    "- EnduroNoFrameskip-v4\n",
    "- PongNoFrameskip-v4\n",
    "\n",
    "Also, **if you want to learn to implement Deep Q-Learning by yourself**, you definitely should look at CleanRL implementation: https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif\" alt=\"Environments\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paS-XKo4-kmu"
   },
   "source": [
    "________________________________________________________________________\n",
    "Congrats on finishing this chapter!\n",
    "\n",
    "If you’re still feel confused with all these elements...it's totally normal! **This was the same for me and for all people who studied RL.**\n",
    "\n",
    "Take time to really **grasp the material before continuing and try the additional challenges**. It’s important to master these elements and having a solid foundations.\n",
    "\n",
    "In the next unit, **we’re going to learn about [Optuna](https://optuna.org/)**. One of the most critical task in Deep Reinforcement Learning is to find a good set of training hyperparameters. And Optuna is a library that helps you to automate the search.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WRx7tO7-mvC"
   },
   "source": [
    "\n",
    "\n",
    "### This is a course built with you 👷🏿‍♀️\n",
    "\n",
    "Finally, we want to improve and update the course iteratively with your feedback. If you have some, please fill this form 👉 https://forms.gle/3HgA7bEHwAmmLfwh9\n",
    "\n",
    "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kc3udPT-RcXc"
   },
   "source": [
    "See you on Bonus unit 2! 🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS3Xerx0fIMV"
   },
   "source": [
    "### Keep Learning, Stay Awesome 🤗"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "DeepRLCourse",
   "language": "python",
   "name": "deeprlcourse-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
